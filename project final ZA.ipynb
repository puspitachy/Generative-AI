{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                   Generative AI Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring creative and  practical use cases of generative AI models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loading libraries and packages\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "#key path- please replace this path with the path of where you API key is located\n",
    "\n",
    "secret_key_path = r\"C:\\Users\\puspi\\OneDrive - Yeshiva University\\MSC AI Sem-1\\key.txt\"\n",
    "with open(secret_key_path, 'r') as file: #opening key file\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "# Setting the OpenAI API key\n",
    "\n",
    "openai.api_key = api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: openai\n"
     ]
    }
   ],
   "source": [
    "pip show openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image generate using model DALLÂ·E by describing what type of image user wants to generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-1M9gAaDY2si2E9aDjMZUbRP2/user-QLx6X0xUYZXJxlGxwdjwSGm9/img-YgQttZhYJLQTSldtNxaUuAxu.png?st=2025-05-05T22%3A04%3A37Z&se=2025-05-06T00%3A04%3A37Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=52f8f7b3-ca8d-4b21-9807-8b9df114d84c&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-05-05T17%3A56%3A15Z&ske=2025-05-06T17%3A56%3A15Z&sks=b&skv=2024-08-04&sig=d10MGYDesPBC%2BZbAaQ75utG%2BRWXSQ7QPN6knxWF%2BCYM%3D\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_pic = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "# output section\n",
    "ans = output_pic.images.generate(\n",
    "    model=\"dall-e-3\",  # or \"dall-e-2\"\n",
    "    prompt=\"A cat is going to a library wearing skirts and top also wearing a sunglass, make it more realistic give some people around who is looking at her\",\n",
    "    size=\"1024x1024\",\n",
    "    n=1\n",
    ")\n",
    "\n",
    "#  image can viewd in the URL\n",
    "image_view_link = ans.data[0].url\n",
    "print(image_view_link)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a mental health chat bot using model gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please write how you are feeling i am feeling very low. please help\n",
      "\n",
      "==================== Answer ====================\n",
      "\n",
      "I'm so sorry to hear that you're feeling this way. Just know that you are not alone in this. It's okay to feel low sometimes, and it's important to remember that these feelings will pass. Remember that you are strong, resilient, and capable of overcoming any challenges that come your way. You are worthy of love and kindness, and I'm here to support you in any way I can. Please remember that there is hope and brighter days ahead. You are loved and valued, and I believe in your strength and resilience.\n",
      "\n",
      "Please write how you are feeling i am suicidal\n",
      "\n",
      "==================== Answer ====================\n",
      "\n",
      "I'm so sorry to hear that you're feeling this way. You are not alone, and there are people who care about you and want to help. Please remember that things can get better, and you deserve support and love. It takes incredible strength to reach out, and I want to commend you for that. Remember, you are a valuable and precious person, and there is hope for a brighter tomorrow. Please consider reaching out to a mental health professional or a trusted loved one for support. You are loved and you are not alone.\n",
      "\n",
      "Please write how you are feeling exit\n",
      " you are existing this chat. Come back whenever you feel lonely or sad. i am here for you\n"
     ]
    }
   ],
   "source": [
    "def gpt_prompt():\n",
    "    print(\"This is mental health chatbot. lets talk what is bothering you. i am here to help\")\n",
    "    \n",
    "    \n",
    "while True:  # infinite loop until user quits\n",
    "        # getting user input \n",
    "        \n",
    "        user_input = input(\"\\nPlease write how you are feeling \")\n",
    "        \n",
    "        # check if user wants to exist the task\n",
    "       \n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:  # for closing prompt\n",
    "            print(\" you are existing this chat. Come back whenever you feel lonely or sad. i am here for you\")\n",
    "            break\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            output = openai.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",  # using model 3.5-turbo to save credits\n",
    "           messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\", \n",
    "                        \"content\": \" You are mental health asstant like a psychotherapist. If user tells anything sad about their life or themselves console them. use very lovely tonue and tell them they are not alone. \"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": user_input\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "\n",
    "       #  the output for the question\n",
    "            answer = output.choices[0].message.content.strip()\n",
    "            \n",
    "            \n",
    "            #  formatting text size\n",
    "            print(\"\\n\" + \"=\" * 20 + \" Answer \" + \"=\" * 20 + \"\\n\")\n",
    "            print(answer)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # handle different types of error\n",
    "            print(f\"\\Error: {str(e)}\")\n",
    "            print(\"not working\")\n",
    "\n",
    "if __name__ == \"gpt_prompt\":\n",
    "    gpt_prompt()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please write how you are feeling i am feeling very low. please help\n",
      "\n",
      "==================== Answer ====================\n",
      "\n",
      "I'm so sorry to hear that you're feeling this way. Just know that you are not alone in this. It's okay to feel low sometimes, and it's important to remember that these feelings will pass. Remember that you are strong, resilient, and capable of overcoming any challenges that come your way. You are worthy of love and kindness, and I'm here to support you in any way I can. Please remember that there is hope and brighter days ahead. You are loved and valued, and I believe in your strength and resilience.\n",
      "\n",
      "Please write how you are feeling i am suicidal\n",
      "\n",
      "==================== Answer ====================\n",
      "\n",
      "I'm so sorry to hear that you're feeling this way. You are not alone, and there are people who care about you and want to help. Please remember that things can get better, and you deserve support and love. It takes incredible strength to reach out, and I want to commend you for that. Remember, you are a valuable and precious person, and there is hope for a brighter tomorrow. Please consider reaching out to a mental health professional or a trusted loved one for support. You are loved and you are not alone.\n",
      "\n",
      "Please write how you are feeling exit\n",
      " you are existing this chat. Come back whenever you feel lonely or sad. i am here for you\n"
     ]
    }
   ],
   "source": [
    "def gpt_prompt():\n",
    "    print(\"This is mental health chatbot. lets talk what is bothering you. i am here to help\")\n",
    "    \n",
    "    \n",
    "while True:  # infinite loop until user quits\n",
    "        # getting user input \n",
    "        \n",
    "        user_input = input(\"\\nPlease write how you are feeling \")\n",
    "        \n",
    "        # check if user wants to exist the task\n",
    "       \n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:  # for closing prompt\n",
    "            print(\" you are existing this chat. Come back whenever you feel lonely or sad. i am here for you\")\n",
    "            break\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            output = openai.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",  # using model 3.5-turbo to save credits\n",
    "           messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\", \n",
    "                        \"content\": \" You are mental health asstant like a psychotherapist. If user tells anything sad about their life or themselves console them. use very lovely tonue and tell them they are not alone. \"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": user_input\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "\n",
    "       #  the output for the question\n",
    "            answer = output.choices[0].message.content.strip()\n",
    "            \n",
    "            \n",
    "            #  formatting text size\n",
    "            print(\"\\n\" + \"=\" * 20 + \" Answer \" + \"=\" * 20 + \"\\n\")\n",
    "            print(answer)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # handle different types of error\n",
    "            print(f\"\\Error: {str(e)}\")\n",
    "            print(\"not working\")\n",
    "\n",
    "if __name__ == \"gpt_prompt\":\n",
    "    gpt_prompt()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Giving Prompt to the assiatnt for generating response using model GPT-4o mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os.path\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.discovery import build\n",
    "load_dotenv()\n",
    "# === CONFIG ===\n",
    "SCOPES = ['https://www.googleapis.com/auth/calendar.readonly']\n",
    "TOKEN_PATH = 'token.json'\n",
    "CREDS_PATH = '/Users/pranav/Documents/Yeshiva/Assignments/AI/final_project/credentials.json'\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# ---------- 1. Define system prompt ----------\n",
    "system_prompt = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": (\n",
    "        \"You are a personalized assistant. Help users with calendar events, reminders, and quick answers from the web. \"\n",
    "        \"If a user asks something like 'Do I have a meeting tomorrow?', use their calendar to answer.\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# === AUTH ===\n",
    "def get_credentials():\n",
    "    creds = None\n",
    "    if os.path.exists(TOKEN_PATH):\n",
    "        creds = Credentials.from_authorized_user_file(TOKEN_PATH, SCOPES)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(CREDS_PATH, SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open(TOKEN_PATH, 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return creds\n",
    "\n",
    "# === CALENDAR ===\n",
    "def get_upcoming_events(service, max_results=5):\n",
    "    now = datetime.datetime.now(datetime.UTC).replace(tzinfo=None).isoformat() + 'Z'\n",
    "    events_result = service.events().list(\n",
    "        calendarId='primary', timeMin=now,\n",
    "        maxResults=max_results, singleEvents=True,\n",
    "        orderBy='startTime').execute()\n",
    "    events = events_result.get('items', [])\n",
    "    return events\n",
    "\n",
    "def format_events(events):\n",
    "    if not events:\n",
    "        return \"No upcoming events found.\"\n",
    "    result = \"\"\n",
    "    for event in events:\n",
    "        start = event['start'].get('dateTime', event['start'].get('date'))\n",
    "        result += f\"- {event['summary']} at {start}\\n\"\n",
    "    return result\n",
    "\n",
    "# === AI INTERPRETER (basic intent matching) ===\n",
    "def get_intent(user_input):\n",
    "    keywords = [\"next events\", \"calendar\", \"upcoming\", \"schedule\"]\n",
    "    if any(word in user_input.lower() for word in keywords):\n",
    "        return \"get_events\"\n",
    "    return \"unknown\"\n",
    "\n",
    "# === MAIN ASSISTANT ===\n",
    "def ai_assistant():\n",
    "    print(\"Hi! I'm your personal AI assistant. Ask me about your Google Calendar.\")\n",
    "    creds = get_credentials()\n",
    "    service = build('calendar', 'v3', credentials=creds)\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            print(\"Assistant: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        intent = get_intent(user_input)\n",
    "        if intent == \"get_events\":\n",
    "            events = get_upcoming_events(service)\n",
    "            # print(\"Assistant:\\n\" + format_events(events))\n",
    "            if events:\n",
    "                calendar_summary = \"\\n\".join([f\"{format_events(events)}\" for event in events])\n",
    "                calendar_message = f\"Here are your upcoming events:\\n{calendar_summary}\"\n",
    "            else:\n",
    "                calendar_message = \"You have no upcoming events.\"\n",
    "            print(\"Assistant: \" + calendar_message)\n",
    "        else:\n",
    "            calendar_message = \"You have no upcoming events.\"\n",
    "\n",
    "        # Step 3: Compose message history\n",
    "            messages = [\n",
    "                system_prompt,\n",
    "                {\"role\": \"user\", \"content\": user_input},\n",
    "                {\"role\": \"user\", \"content\": calendar_message}\n",
    "            ]\n",
    "            # Step 4: Query GPT\n",
    "            response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "            bot_reply = response.choices[0].message.content\n",
    "            print(\"\\nAssistant:\", bot_reply)\n",
    "\n",
    "# === RUN ===\n",
    "if __name__ == '__main__':\n",
    "    ai_assistant()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarization of text using  BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "text_summary = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "text = \"\"\"\n",
    "Artificial Intelligence now dominating the world. People are now thinking if their work will be replace by AI or not. Students who are studying are very cautious thinking they will get job after completing their study. AI can cut 40% job which might put many people on unemployment risk. Ai is undoubtly a revoultunary field. Our day to day task has now been becoming very all thanks goes tyo AI. Howver, we need to be carefull of how we are using AI too. As relying on AI will decrese productivity and people will stop logical thinking. Use AI for assuatnmce but dont rely on it for everything.\n",
    "\"\"\"\n",
    "# text length provided-\n",
    "summ = text_summary(text, max_length=100, min_length=25, do_sample=False)\n",
    "\n",
    "print( \"\\n Summerized text:\\n\")\n",
    "print(summ[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": (\n",
    "        \"You are a personalized assistant. Help users with calendar events, reminders, and quick answers from the web. \"\n",
    "        \"If a user asks something like 'Do I have a meeting tomorrow?', use their calendar to answer.\"\n",
    "    )\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
